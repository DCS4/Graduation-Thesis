% !TeX root = ../Template.tex
% [绪论]
% 此处为本LaTeX模板的简介
\chapter{绪论}
计算机视觉是指利用计算机自动处理图像数据，以解决计算机无法通过人眼看到的图像问题的技术。
三维重建是指通过计算机视觉技术和图像处理技术，对真实世界中的物体进行三维建模的过程。三维重建技术可以帮助我们获取物体的准确三维信息，它可以帮助我们更好地理解和分析真实世界的物体，并且可以为计算机图形学、机器人、虚拟现实等应用提供基础。例如，在计算机图形学中，三维重建技术可以用来创建真实世界中的场景；在机器人领域，三维重建技术可以用来帮助机器人更好地感知环境；在虚拟现实领域，三维重建技术可以用来创建虚拟场景。RGB-D深度相机出现，可以同时捕捉图像和深度信息，为计算机视觉、机器人技术、虚拟现实等应用提供强大的数据支持。借助于RGB-D相机可以方便进行三维重建和纹理重建，极大的减少重建成本，恢复出更精确的三维场景的结构和纹理信息。

%%============================
\section{研究背景与意义}
从图片和视频中恢复出三维场景是计算机视觉领域重要目标之一，也是三维重建领域的核心研究内容，场景理解与分割的重要研究基础。三维重建有很多应用前景，例如在建筑、汽车制造、医疗、无人机、游戏、电影制作等领域都有广泛的应用。例如，在建筑领域，三维重建可以用来制作建筑物的三维模型，方便设计和建造；在医疗领域，可以用来制作身体的三维模型，帮助医生进行手术规划；在无人机领域，可以用来制作地面的三维模型，帮助无人机更好的导航；在电影制作领域，可以用来制作电影中的三维场景，更好的让观众感受到故事的真实感。\par
单纯的RGB图片无法正确恢复出场景的三维结构，因为RGB图片具有二义性，无法判断图片中的物体的远近关系，需要深度数据的参与。早期，三维重建没有直接的深度数据可得，需要利用多视角之间的视差关系，估计出深度图。受深度数据的影响，三维重建时间长，精度低，重建出的场景无法让人满意。得益于深度相机的出现，为我们重建出接近于真实场景的三维模型提供了可能。由于深度相机可以直接获取从相机光心到物体表面每个点的距离，所以基于RGB-D相机的三维重建技术不仅能达到实时性而且能获取场景精细结构。\par
虽然RGB-D相机可以获取准确的深度数据，从而提高重建模型质量。但是深度相机分辨率较低，容易丢失微小细节。不仅如此，深度相机采用红外光测量距离，容易受太阳光和室内其他光源的影响，产生深度测量噪声。并且相机本身在制造过程中可能会出现镜头变形，从而拍摄图片出现桶形畸变和枕形畸变使得三维模型顶点投影至平面时发生错位现象。以上深度相机固有的缺陷使得测量数据含有噪声，从而造成三维重建模型的瑕疵和高频细节的缺失。除此之外，三维重建时往往采用增量式融合方法，需要把每一帧的深度数据融合到全局模型中，而且每一帧的相机位姿估计依赖于前一帧，由于估计误差不可避免，这种误差一直会累计并传递至下一帧，发生相机位姿漂移现象。即使有回环检测等位姿修正方法，但是位姿误差仍然无法消除，造成重建出的三维模型顶点偏离预期位置。再者，生成纹理贴图时，三维模型中每个顶点会投影至每个彩色图片上收集颜色。由于几何误差和相机位姿估计误差的存在，每个顶点投影至不同视角的RGB图片时会得到不同的颜色，造成纹理映射出现模糊伪影现象。\par
由于存在以上误差，纹理映射结果无法让人满意，还需要人工后处理才能应用至其他领域。要想获取清晰纹理，必须首要解决相机位姿估计不准确的问题，再者解决由于几何误差导致纹理不能和几何模型对齐的影响。先前的工作在提升纹理映射质量方面做出了许多努力。一些方法致力于提升重建模型质量，间接提高纹理映射结果，一些方法采用扭曲方法弥补相机位姿的误差，还有方法采用联合优化方法，矫正相机位姿、恢复三维重建模型几何细节，估计场景光源，共同提升几何和纹理质量。受可微分渲染方法在单视图三维重建领域的成功，本文方法首先采用可微分渲染方法优化相机位姿，再将可微分渲然模块嵌入对抗神经网络中，合成貌似真实的纹理图。除此之外，本文基于可微分渲染又提出联合优化框架，不仅能提升纹理质量而且能提升几何模型的高频细节，从而得到高保真的纹理。\par
综上所述，本文提出利用可微分渲染优化相机位姿和用对抗神经网络合成纹理策略解决纹理映射中存在的模糊伪影问题。在第一个框架基础上提出联合优化方法，提升几何模型重建质量，弥补纹理与几何模型存在的错位现象，从而获得高保真的纹理。
%%============================
\section{研究现状}
\subsection{三维重建}
三维重建技术错综复杂，随着视觉传感器的进步也不断催生出各种三维重建算法。基于RGB-D相机的三维重建技术来源于SLAM（Simultaneous Localization and Mapping），是计算机视觉中的一种技术，它可以通过观察周围的环境来确定机器人的位置和场景的地图。根据传感器的不同可以分为视觉SLAM、激光雷达SLAM、RGB-DSLAM等。这里为了方便，RGBD相机出现以前的SLAM技术，统称为传统SLAM。相比于传统SLAM，基于RGB-D相机的三维重建既采用深度信息也采用彩色信息，并且深度信息为主体，而传统的SLAM主要用彩色信息。其次侧重点也不相同，传统SLAM以定位为主体，建图次之，而且以稀疏图为主。基于RGB-D相机的三维重建以建图为主体，构建稠密高质量的地图以满足实际应用需求。自KinectFusion~\cite{RichardNewcombe2011KinectFusionRD}利用RGB-D相机实时重建出精密地图，效果惊艳，引发了RGB-D SLAM的潮流。所以后续大部分重建作品为了保持一致，名称中均带有fusion，所以基于RGB-D相机的三维重建与基于Fusion的三维重建的说法等价。基于RGB-D相机的三维重建可以细分为静态/动态场景的重建，但是本课题纹理优化主要基于静态场景，所以本文只叙述静态重建相关工作。\par
2011年以KinectFusion\cite{RichardNewcombe2011KinectFusionRD}为典型代表的重建问世
，使用Kinect传感器采集的深度数据实时融入到TSDF（Truncated Signed Distance Function）表示的模型中。TSDF是通过构建体素空间重建三维实体，并且体素空间分为多个小块，每个体素小块存储该小块与其最近的物体表面的距离。KinectFusion使用帧到模型的迭代最近点算法跟踪当前帧与全局模型的对应关系，获取每帧图像的相机位姿变化。但是由于采用稠密体积表示，消耗内存，并且易受相机位姿误差影响，所以很难重建大型场景。Thomas Whelan等人扩充了KinectFusion系统，提出了较为完备的Kintinuous~\cite{ThomasWhelan2012KintinuousSE}。它融合了回环检测和回环优化，以抵抗位姿估计中的噪声。并且使用变形图做非刚性变换，更新点的坐标，适合大场景的三维重建。进一步地，Thomas Whelan又提出ElasticFusion~\cite{ThomasWhelan2015ElasticFusionDS},采用面元（Surfel）的表示方法，用于小型场景的重建。它将模型到模型的局部回环和全局回环检测结合重建地图，并通过优化地图方式保证重建结果的全局一致性。Prisacariu等人提出InfiniTAM v3~\cite{VictorAdrianPrisacariu2017InfiniTAMVA},跨平台实时的大范围深度信息融合与跟踪框架，利用哈希表存储隐式体积表示，因而能重建比KinecFusion更大范围的3D环境。ANGELA DAI等人提出并行化的优化框架Bundlefusion~\cite{AngelaDai2016BundleFusionRG}利用光束平差法（BA）来优化三维重建模型中相机的位置和物体的三维坐标，使得重建结果与观测数据之间的误差最小。充分利用基于稀疏特征以及稠密几何和光度匹配提出的对应关系，合并多个观测模型提高三维重建结果的精度。最近，神经辐射场在三维重建领域大放异彩，Dejan等人~\cite{DejanAzinovic2021NeuralRS}提出基于神经辐射场的非实时三维重建框架，利用神经网络存储符号距离场（SDF）隐式表达重建模型，可产生比单独使用基于颜色或深度数据的方法更详细和完整的重建结果。\par
虽然以上方法采用各种方法试图抵抗重建过程中采集的深度数据噪声以及估计相机位姿的累计误差，以及不同表面之间固有的缺陷使得生成的三维模型仍然存在几何细节丢失，瑕疵等现象。

\subsection{纹理优化}
在三维重建中，除了重建出物体和场景的高质量的几何模型之外，人们往往更加 专注于场景与物体的外观，也就是场景和物体的材质和纹理颜色。要恢复三维重建模 型的纹理颜色就需要我们对重建的模型进行纹理映射。好的纹理映射结果可以弥补三 维重建中几何模型的缺陷，并生成逼真的纹理映射的结果。在一些应用中，重建模型 的纹理映射的要求比重建高质量的几何模型的要求更高，这就需要重建出更高质量的 纹理结果。特别是在一些虚拟现实、增强现实、虚拟试衣以及数字游戏等应用中。认 识到纹理映射的重要性之后，近几年三维重建工作者在三维重建纹理映射方面进行了 大量地研究，并取得了一些显著的进展。
三维重建旨在利用计算机技术构建真实场景，除了重建出几何模型，外观模型也是必要的，而且人们往往更加关注三维物体的外观。高质量的纹理映射不仅能弥补几何重建中的缺陷而且能进行纹理编辑从而实现外观自由控制。但是重建高保真的纹理映射比单纯的几何重建更加具有挑战性，因为人眼往往对外观存在的伪影模糊裂缝等现象更加敏感。 \par
为了恢复三维重建模型高保真的纹理细节，近十几年，专家学者在三维重建领域做出了许多努力，在实现三维重建与纹理映射方面取得的显著的进展。本文从影响纹理优优化结果的不同因素:不精确的相机位姿、几何模型和纹理出发,按不同的优化思路把相关的算法分为一下几类。\par
\vspace*{2mm}\noindent{\bf 基于面投影的方法：}它为每个面片选择最佳视角Lempitsky等人~\cite{lempitsky2007seamless}使用成对儿的马尔可夫随机场为几何模型生成纹理图集。其中数据项为每个面片寻找最佳视图，平滑项最小化纹理块之间的细缝，通过图割和$alpha$膨胀~\cite{boykov2001fast}最小化能量函数。这种方法面临一个具有挑战性的问题，即如何减轻相邻纹理之间的视觉接缝：由于相机参数或重建的几何形状略微不准确，纹理补丁可能会在边界处不对齐，产生重影，并导致强烈可见的接缝。Lempitsky等人提出全局颜色矫正方案，调整将不同块边界顶点颜色，以使得相邻块之间的颜色充分接近。Waechter等人~\cite{waechter2014let}改进了一种全局色彩调整算法，不仅考虑相邻顶点之间的颜色差异额外考虑相邻边的颜色得到更为鲁棒的结果，在全局颜色调整后，使用泊松编辑调整目标图像区域的边界像素颜色，进一步减少细缝。Fu等人~\cite{fu2018texture} 提出了一种全局到局部的非刚性优化方法来调整摄像机的姿态漂移，利用重投影误差优化相机外参，并提出局部扭曲纹理坐标方法，纠正几何误差引起的纹理坐标漂移。基于面投影地方法，能得到清晰的全局纹理，但是由于相机曝光、位姿、几何误差等影响因素无法完全消除，因而会产生未对齐地局部纹理。\par
\vspace*{2mm}\noindent{\bf 基于顶点的方法：}这种方法为三维模型顶点赋予颜色。将三位模型中每个顶点投影至可见的彩色图像上得到颜色，然后利用加权平均算法计算出该顶点的最终颜色，重复此步骤直到生成所有顶点的纹理。这种算法对相机位姿误差十分敏感，因为基于光度一致性假设顶点投影至不同视角会得到相同颜色，但是由于重建模型中各种误差，使得投影顶点会得到不同颜色，加权平均后发生颜色模糊现象。Zhou等人~\cite{zhou2014color}设计了一个纹理映射框架，通过刚性形变优化相机位姿，进一步通过局部图像的非刚性变形来进一步弥补相机位姿估计误差和几何重建误差。但该方法需要对网格模型进行细分，这将大大增加数据量，限制了通用性。\par
\vspace*{2mm}\noindent{\bf 基于块合成的方法：}基于块的方法来源于图像编辑~\cite{Barnes:2009:PAR}，借助于代替纹理优化方案，基于块合成方案通过为每个源图像合成一个对齐的图像，我们纠正了由几何、相机姿势和输入图像的光学畸变引起的不对准。Bi等人~\cite{bi2017patch}采用基于 patch 的图像合成方法来生成一个新的完全对齐的目标纹理图像 来消除纹理图像之间的不对齐，从而避免纹理结果的模糊和重影。最近fu等人~\cite{fu2021seamless}提出新的纹理映射方法，使用一个三向相似度函数来重新合成纹理图边界条纹内的图像上下文，减少纹理接缝的出现。最后引入全局颜色协调方法来解决从不同视点捕获的纹理图像之间的颜色不一致，生成视觉逼真的纹理映射结果。基于块的合成方案不仅用与纹理块合成而且用于纹理补洞等其他应用。\par
\vspace*{2mm}\noindent{\bf 基于联合优化的方法：}联合优化方案对重建过程中各种误差，分别进行优化，并使用交替循环策略进行联合优化。Robert Maier等人~\cite{RobertMaier2017Intrinsic3DH3}提出了一种基于SFS（shape-from-shading）和空间变化的球谐光照函数的子体优化方法，同时优化几何、纹理、相机姿态和场景照明。可以获得纹理一致的高质量三维重建。但该方法依赖于SFS，需要分解场景的光照，容易导致纹理拷贝问题。最近工作中Fu等人~\cite{YanpingFu2020JointTA}提出根据颜色和几何一致性以及高频法线线索对重建网格进行优化，有效地克服了SFS产生的纹理拷贝问题，从而得到了更加高质量的重建结果。这种方法相比之前只优化纹理方法，在几何模型重建细节缺失较大时，仍然能产生清晰纹理。基于此本文第二个工作也提出联合优化框架实现更加鲁棒的结果。\par
\vspace*{2mm}\noindent{\bf 基于深度学习的方法：}对抗生成网络~\cite{NIPS2014_5ca3e9b1}强大拟合能力在图像翻译领域大放异彩，合成与真实世界充分接近的彩色图片，例如优秀开源框架pix2pix~\cite{isola2017image}cycleGAN~\cite{  zhu2017unpaired}等。受基于块合成纹理方法启发，Huang等人~\cite{JingweiHuang2020AdversarialTO}使用从弱监督视图中获得的条件对抗损失为近似表面生成逼真的纹理，使用基于学习的方法训练纹理目标函数，以保持对摄像机姿态和几何畸变的鲁棒性。与我们相似的工作zhang等人~\cite{9705143}借助于可微分渲染方法提出了一种联合优化方法，将几何、纹理和相机姿态共同纳入一个统一的优化框架中，并采用一种自适应交织策略，提高优化的稳定性和效率。与我们的方法类似但是我们的方法在优化几何时采用自适应性细分，从而当几何误差过大时，我们的方法仍能恢复出到几何模型的细节，并能获取高保真的纹理。
\subsection{可微分渲染}
可微分渲染是通过梯度设计，能够将渲染输出的梯度方向传播至三维实体，从而弥补了二维和三维之间的差距，同时可以允许神经网路在操纵渲染图像的同时优化三维实体，无需额外的三维标注。基于不同的三维实体如体素、点云、SDF、网格有不同的可微分渲然方法，因为网格能够表达三维模型的拓扑结构，又无需关注三维实体内部的构成，这种表示方式不仅灵活而且节省内存，所以本文只关注基于网格的可微分渲染。
Loper和Black~\cite{MatthewLoper2014OpenDRAA}设计了基于网格的通用框架OpenDR，近似可微渲染器。Kato等人~\cite{MatthiasNiener2013Realtime3R}提出了一种神经3D网格渲染器，用手工设计的函数来近似光栅化后向梯度。SoftRas~\cite{ShichenLiu2019SoftRA}以概率方式将每个像素分配给网格的所有面，保证前向后向操作均可微。pytorch3d~\cite{ravi2020pytorch3d}基于SoftRas方法，设计出通用的基于网格的可微分框架，不仅方便地更新几何模型而且还能操作纹理贴图。我们的方法基于pytorch3d，借助于可微分渲染框架，将梯度反向传播并更新场景中相机位姿，几何和纹理贴图。最近fuji等人依据DIB-R~\cite{chen2019_dibr}发布基于网格的可微分框架Kaolin~\cite{KaolinLibrary}能额外对材质进行编辑。为了聚焦于获取高保真纹理，在本文中除了几何模型与纹理图集，并未考虑场景中其他参数，例如材质，灯光等。更多关于可微分渲染的详细介绍请参阅综述\cite{HiroharuKato2020DifferentiableRA}。
%%----------------------
\section{本文的工作与安排}

\subsection{本文工作}
为了解决目前三维重建纹理映射存在泛化能力差、存在瑕疵等问题，本文工作围绕基于RGB-D相机的纹理映射主题，从三维重建模型的纹理优化与联合优化两个方面做了系统性的研究。\par
生成对抗网络可以学习误差容忍度量，能够对几何、相机位姿、灯光等各项误差容忍，并生成貌似真实的纹理，但是在相机误差过大时，生成的纹理结果仍然存在模糊伪影等现象，因此借助于可微分渲染我们提出优化相机位姿的方法，将模型顶点投影至所有可见的视角得到渲染图片，并于真实采集的数据进行比对产生期望梯度以更新相机位姿。然后使用优化后的相机位姿再用GAN网络~\cite{chanmonteiro2020pi-GAN}重新合成纹理图集。本方法在公共数据集上表现优异，相比于传统方法泛化性更强，而且对于误差较大场景鲁棒。\par
受fu等人联合优化方法启发，我们借助于可微分渲染方法我们优化几何模型顶点位置，为了恢复重建几何模型的高频细节，本文又提出自适应性细分方法，增加顶点面片数目以增强模型重建的合理性和精确性。除此之外，本文提出交替优化策略，首先利用重投影误差优化相机位姿，再经过模型细分后优化顶点位置，显著减少初始模型存在的误差，平滑模型参数中大部分噪声。最后再借助像素生成管线，对于剩余误差进行优化，从而得到高保真的纹理。实验证明我们的结果在各种场景中均能恢复出高保真的纹理，符合真实世界的三维模型。。
\subsection{结构安排}


本文的具体结构如下： \par
第一章 绪论。首先介绍基于RGB-D相机的三维重建与纹理映射背景和研究意义，其次，依照时间顺序
探讨与本文相关的领域：基于fuison的三维重建、纹理映射、基于网格的可微分渲染的国内外研究现状最后介绍本文的研究思路和过程，以及论文的结构安排。\par
第二章 纹理优化相关技术介绍。在本章中，首先介绍数据获取设备，重建场景的表面表示，纹理表示与获取以及可微分渲染的原理。详细描述重建模型的各个组件如何影响纹理映射结果，以及各个部分与纹理映射的关系。\par

第三章 基于可微分渲染然的纹理优化。本章首先利用可微分渲染技术优化相机位姿，再借助对抗生成网络生成纹理图像，并在已有的数据集上验证方法结果。对应于本文第一个工作。\par

第四章 基于自适应细分的重建模型与纹理优化。详细介绍对于RGB-D三维重建模型的联合优化算法，共同优化相机位姿、几何模型与纹理图集。对应于本文第二个工作。\par

第五章 总结与展望。总结本文主要工作，介绍本文方法存在的缺点与不足，并对纹理优化方法未来的研究工作做出展望。

