% !TeX root = ../Template.tex
% [绪论]
% 此处为本LaTeX模板的简介

% \clearemptydoublepage
% \setcounter{figure}{0}
% \setcounter{table}{0}
% \setcounter{algocf}{0}
% \chapter{绪 论}

\chaptera{绪 论}


% 从应用角度来看，三维重建技术可以获取物体的准确三维信息，从而帮助人们更好地理解和分析真实世界的物体，并且可以为计算机图形学、机 
% 器人、虚拟现实等应用提供基础。例如，在计算机图形学中，三维重建技术可以用来创建或者模拟真实世界中的场景；在机器人领域，三维重建 
% 技术可以用来帮助机器人更好地感知环境；在虚拟现实领域，三维重建技术可以用来创建虚拟场景等。

计算机视觉是指利用计算机自动处理图像数据，以解决计算机像人眼一样处理图像问题的技术。三维重建是一种利用计算机视觉和图像处理技术，将真实世界中的物体或场景从二维图像或视频中还原成三维模型的技术过程。RGB-D深度相机能同时捕捉场景颜色信息和深度信息，为计算机视觉、机器人技术、虚拟现实等应用提供了硬件支持。借助于RGB-D相机，可以方便地进行三维重建和纹理重建，极大地减少重建成本，并且可以恢复出精确的三维场景结构和纹理信息。

%%============================

%缺乏图示，vr纹理应用图示，缺乏引用
\section{研究背景与意义}
从图片和视频中恢复出三维场景是计算机视觉领域中的重要研究方向，也是场景理解与分割的重要研究基础。三维重建技术有广泛的应用前景，在建筑、汽车制造、医疗、无人机、游戏、电影制作等领域都有很大的需求。例如，在建筑领域，三维重建技术可以被用于制作建筑物的三维模型，从而更便于设计和建造；而在医疗领域，可以将其用于制作身体的三维模型，帮助医生进行手术规划。在无人机领域，三维重建技术可以被用于制作地面的三维模型，从而更好地辅助无人机的导航；在电影制作领域，三维重建技术可以被用于打造电影中真实的三维场景，从而更好地让观众融入故事情境中。\par
单纯的RGB图像无法准确地恢复出场景的三维结构。由于RGB图像中的物体符合近大远小的规则，导致重叠的物体之间存在深度模糊，无法确定图像中物体的远近关系。因此，需要额外的深度信息来确定图像中物体之间的相对距离。早期的三维重建缺乏直接的深度数据可用，需要利用多个视角之间的视差关系来估计物体深度。然而，这种方法得到的深度误差较高，不仅使得重建过程时间长，而且还可能导致重建结果的不准确，重建出的模型一直无法令人满意。得益于深度相机的出现，现在可以利用该设备获取场景中光线行进路径上的物体与相机之间的距离，重建出具有精细几何细节的稠密三维场景模型。这为三维重建技术的发展提供了硬件支持。RGB-D相机能够直接获取相机光心到物体表面的距离，相比于早期的多视角视差方法，基于该相机的三维重建技术能够实时处理深度数据并在短时间内重建出高精度的场景模型。\par
虽然RGB-D深度相机可以获取相对准确的深度数据，可以提高三维重建模型的效率和准确性。但是，由于深度相机分辨率较低，拍摄图片清晰度不高，重建出模型很容易丢失微小的几何细节。不仅如此，深度相机普遍采用红外光测量距离，容易受太阳光和室内其他光源的影响，产生深度测量噪声与度量误差。并且相机本身在制造过程中可能会出现镜头变形，使得拍摄图片受到切向畸变或者径向畸变影响，导致三维模型顶点投影至平面时发生错位现象。以上深度相机固有的缺陷使得测量数据不可避免地含有噪声，造成三维重建模型的瑕疵和高频几何细节的缺失。三维重建中估计相机位姿时往往采用增量融合的方式，这种方法需要重复地将每一帧的数据与前一帧的结果进行融合，以逐步构建出全局的三维模型。由于估计误差不可避免，这种误差一直会累计并传递至下一帧，导致相机出现漂移现象。即使有回环矫正等位姿修正方法，位姿估计误差也无法完全消除，最终造成重建出的三维模型几何形状偏离预期。在三维模型纹理生成阶段，三维模型中每个顶点会投影至不同彩色图像上以获得顶点颜色。由于几何误差和相机位姿估计误差的存在，同一个顶点投影至不同视角关联的彩色图像时往往会出现偏移，得到不一致的颜色。加权平均后使得纹理映射出现模糊和重影现象。\par
由于存在以上误差，纹理重建结果无法让人满意，在实际应用中仍需人工进行一定的干预。要想获取清晰纹理，必须首要解决相机位姿估计不准确的问题。然后，解决由于几何误差而导致纹理不能和几何模型对齐的瑕疵。先前的工作在提升纹理映射质量方面做出了许多努力。一些方法致力于提升重建模型质量，间接提高纹理映射结果。另外一些方法采用扭曲彩色图像的方法弥补相机位姿的误差。还有一些方法采用联合优化方法，同时矫正相机位姿、恢复三维重建模型几何细节和估计场景光源，来共同提升几何和纹理质量。受可微分渲染方法在单视图三维重建领域\upcite{ShichenLiu2019SoftRA}获得成功的影响，本文采用可微分渲染方法矫正相机位姿，将可微分渲染模块嵌入对抗神经网络中，合成近似真实场景外观的纹理图像。进一步，本文基于可微分渲染提出联合优化框架，不仅能提升纹理质量而且能恢复几何模型的高频细节，得到高保真的纹理。\par
综上所述，本文提出了利用可微渲染矫正相机位姿和采用对抗神经网络合成纹理的策略，以解决纹理映射中存在的模糊和伪影问题。此外，本文在第一个纹理优化框架的基础上，提出了一种联合优化方法，不仅可以提升几何模型重建质量，还可优化纹理以弥补纹理与几何模型存在的错位现象，获得更高保真的纹理模型。
%%============================
\section{研究现状}
\subsection{三维重建}
虽然三维重建技术非常复杂，但随着视觉传感器的进步，不断涌现出各种三维重建算法。其中，基于RGB-D相机的三维重建技术源自于同时定位和地图构建(Simultaneous Localization and Mapping,SLAM)。这是计算机视觉中的一项重要技术，可以通过观察周围环境，确定机器人的位置并重建场景地图。SLAM 涉及多个不同的领域和技术，因此它具有多个分支和分类方法。根据使用的传感器类型不同，SLAM 技术可以分为多类，如视觉SLAM、激光SLAM、惯性SLAM和深度SLAM等。其中，视觉SLAM 利用摄像头或 RGB-D 相机等视觉传感器获取环境图像信息，并通过计算机视觉算法进行处理和分析，能够在未知环境下，对机器人位置和姿态进行估计，并构建地图。在本文中，为了方便起见，将 RGB-D 相机出现之前的视觉 SLAM 技术统称为传统 SLAM。与传统 SLAM 不同，基于 RGB-D 相机的三维重建不仅采用彩色信息，还利用深度信息，并以深度信息为主。传统 SLAM 主要依赖彩色图像信息，其主要目标是定位，次要目标是建图，而且它只能构建稀疏图。基于 RGB-D 相机的三维重建以建图为主体，可以构建稠密高质量的地图，以满足实际应用需求。从 KinectFusion\upcite{RichardNewcombe2011KinectFusionRD} 开始，利用 RGB-D 相机实时重建完整且精密的地图，引发了以 RGB-D 相机作为传感器的 SLAM 技术热潮。后续大部分重建算法为了保持一致，算法名称中均带有单词 “Fusion”，因此基于 RGB-D 相机的三维重建和基于 Fusion 的三维重建是等价的。基于 RGB-D 相机的三维重建可以进一步细分为静态场景的重建和动态场景的重建，但是本文研究的纹理优化是基于静态场景的，因此接下来只介绍静态场景相关的工作。\par

2011年，以KinectFusion为代表的三维重建算法问世，它使用Kinect传感器采集的深度数据，实时融入到截断符号距离场（Truncated Signed Distance Function,TSDF）模型表示中。TSDF是一种三维重建技术，通过将物体所在的空间分割成多个小的立方体块来构建三维实体。每个立方体块的数值表示该块与其最近的物体表面之间的距离。KinectFusion使用帧到模型的最近邻迭代算法（Iterative Closest Points Algorithm,ICP），根据当前帧与全局模型的对应关系，获得每帧图像的相机位姿变换。由于采用稠密体积表示，内存开销大，并且易受相机位姿估计误差影响，因此很难重建大型场景的三维模型。Thomas Whelan等人\upcite{ThomasWhelan2012KintinuousSE}提出了更完备的三维重建系统Kintinuous。相较于KinectFusion，Kintinuous融合了回环检测和回环矫正，以避免位姿估计误差积累导致相机跟踪失败。此外，它使用变形图进行非刚性变换，通过更新模型顶点的空间坐标，减少误差积累，更适合大场景的三维重建。
进一步地，Thomas Whelan等人\upcite{ThomasWhelan2015ElasticFusionDS}提出了采用面元素（Surfel）而非体素的模型表示方法的ElasticFusion。它可以实时捕获稠密的表面地图，并且能够检测多个光源的位置，提高地图质量、跟踪精度和鲁棒性。但是，它需要较高的内存和计算资源，更适合小场景的重建。Prisacariu等人\upcite{VictorAdrianPrisacariu2017InfiniTAMVA}提出了InfiniTAM v3，用于在大范围场景中进行深度信息融合和跟踪的跨平台实时跟踪框架。它采用哈希表来存储隐式体积表示，能够重建比KinectFusion更大范围的3D环境。Angela Dai等人\upcite{AngelaDai2016BundleFusionRG}提出并行化的优化框架Bundlefusion，利用光束平差法（Bundle Adjustment,BA）来优化三维重建模型中相机的位置和物体的三维坐标，以使得重建结果与观测数据之间的误差尽可能小。同时，它利用RGB-D相机采集的彩色和深度图像，通过在线表面重整和全局位姿矫正，得到全局一致的三维重建结果。

最近，神经辐射场（Neural Radiance Fields,Nerf）技术在三维重建领域迅速发展。Dejan等人\upcite{DejanAzinovic2021NeuralRS}提出了基于神经辐射场的非实时三维重建框架，利用神经网络存储符号距离场的隐式表达，得到比单独使用基于颜色或深度数据的方法更详细和完整的重建结果。\par

虽然以上的方法采用各种不同的策略抵抗了在重建过程中采集到的深度数据噪声以及估计相机位姿的累计误差，但是由于重建算法固有的缺陷，生成的三维模型仍然存在几何细节丢失和瑕疵等现象。

\subsection{纹理优化}
三维重建利用计算机技术构建真实场景，需要准确恢复场景的几何形状和表面外观，通过正确的纹理映射可以恢复三维模型的表面颜色。高质量的纹理映射不仅可以掩盖不精确的几何细节，还可以使三维模型更真实。例如，凹凸贴图和海浪贴图等基于纹理贴图的技术在游戏中被广泛应用，以提高游戏场景的真实感。然而，高保真的纹理映射是一项具有挑战性的技术，因为人眼对场景的外观缺陷非常敏感。在纹理映射过程中，需要克服伪影、模糊和裂缝等问题。虚拟现实、混合现实、增强现实等领域中，对重建高保真纹理映射的需求往往比单纯的几何重建要求更高且更具挑战性。好的纹理映射结果可以隐藏几何模型细节，降低重建几何模型的成本，达到几何与纹理、材质模型解耦合的目的，实现模型外观的自由控制。然而，纹理细节也会像三维模型重建一样遭受各种噪声和估计误差的影响。此外，保证纹理与几何模型的正确映射关系也是一个挑战。总之，纹理的优化、重建、映射实质上是借助于优化算法减小重建误差、度量误差和抵抗噪音，从而恢复出真实场景外观的过程。\par 
为了提高三维重建模型的纹理质量，近年来，许多国内外专家和学者在三维重建领域做出了大量工作\upcite{fuyanping,tongliyang,maolibo}，并在实现三维重建与纹理映射方面取得了显著进展。本文从影响纹理优化结果的因素出发，按不同的优化思路将相关算法分为以下几类。\par

\vspace*{2mm}\noindent{\bf 基于面投影的方法：}这类方法首先为每个三角形面片选择一张最合适的彩色图像，然后将三角形面片投影到图片上生成面纹理，并存储在二维图像上。同时，计算每个顶点的UV坐标，建立模型顶点和纹理图像像素的映射关系。Lempitsky等人\upcite{lempitsky2007seamless}使用成对儿的马尔可夫随机场建立能量函数，为每个面片寻找最清晰的图片。其中，能量函数的数据项表示为每个面片寻找最佳视图，平滑项表示最小化纹理块之间的细缝。最后，通过图割和$\alpha$膨胀\upcite{boykov2001fast}最小化能量函数，为三维模型生成清晰的纹理图像。采用面投影方法生成纹理图像面临一个挑战，即如何降低相邻纹理块之间的视觉不连续性。其根源在于相机位姿估计不准或重建的几何形状存在缺陷，导致纹理图像和模型发生错位而出现视觉裂缝。Lempitsky等人提出全局颜色校正方案，调整不同块边界顶点的颜色，以使相邻块之间的颜色趋近一致。Waechter等人\upcite{waechter2014let}对此进行了改进并提出了一种新的全局色彩调整算法，不仅考虑相邻顶点之间的颜色差异，还额外考虑了相邻边的颜色，得到更为鲁棒的结果。在全局颜色调整之后，接着使用泊松编辑\upcite{PrezPatrick2003PoissonIE}调整目标图像区域的边界像素颜色，进一步减少细缝。Fu等人\upcite{fu2018texture}提出了一种全局到局部的非刚性优化方法来校正相机的位姿漂移。利用重投影误差优化相机外参，并提出局部扭曲纹理坐标方法，以纠正几何误差引起的纹理坐标漂移。由于相机曝光、位姿和几何误差等因素无法完全消除，以上基于面投影的方法，在局部区域都会产生未完全对齐的纹理块。\par


\vspace*{2mm}\noindent{\bf 基于顶点加权融合的方法：}这类方法为三维模型的顶点赋予颜色，直接作为物体表面纹理\upcite{franken2005minimizing,eisemann2008floating,dellepiane2011flow,wu20083d,aganj2010multi}。具体地，首先将三维模型中每个顶点投影到可见的彩色图像上，得到初始颜色，然后利用加权平均算法计算出该顶点的最终颜色，重复此步骤直到生成所有模型顶点的颜色纹理。这类方法对相机位姿误差十分敏感。基于光度一致性假设，顶点投影到不同视角时应该得到相同颜色，但由于重建模型中存在各种误差，顶点可能会投影到错误的位置得到不一致的颜色，加权平均后会出现模糊现象。为了弥补相机估计误差，Zhou等人\upcite{zhou2014color}采用了模型顶点的重投影误差矫正相机位姿，并对图像施加变形场的方法。该方法以顶点颜色表示整个场景的纹理，为了得到更清晰的外观颜色，需要在优化之前细分网格模型，增加顶点数。然而，这会显著增加计算代价和内存代价，限制算法的适用范围。\par



\vspace*{2mm}\noindent{\bf 基于块合成的方法：}基于块的方法源于图像编辑\upcite{Barnes:2009:PAR}。与以往的纹理优化方案不同，基于块合成方案为每个图像合成一个与三维模型对齐的纹理图像，纠正由几何、相机姿势和光学畸变引起的图像失真。Bi等人\upcite{bi2017patch}借助图像和视频编辑任务领域的块合成技术，首次提出纹理图像合成算法，保留原始图像内容的同时，为几何模型生成一张完全对齐的纹理图像，避免纹理映射结果中的模糊伪影以及裂缝现象。
最近Fu等人\upcite{fu2021seamless}提出了一种新的纹理映射方法。该方法使用一个三向相似度函数来重新合成纹理图边界内条纹的图像上下文，减少纹理接缝的出现。此外，额外引入了全局颜色协同方法来解决从不同视点捕获的纹理图像之间的颜色不一致问题，最终生成视觉逼真的纹理映射结果。基于块的合成方案简单灵活，计算代价低，并能显著减少纹理模糊现象。这种方案不仅可以用于纹理块合成，还可以用于其他视觉应用，如纹理补洞、图像修复等。\par

\vspace*{2mm}\noindent{\bf 基于联合优化的方法：}联合优化方案对重建过程中各种误差进行优化纠正，并使用交替循环策略进行联合优化。Robert Maier等人\upcite{RobertMaier2017Intrinsic3DH3}提出了一种基于阴影恢复形状\upcite{zhang1999shape}（shape-from-shading,SFS）和空间变化的球谐光照函数的子体优化方法，该方法同时优化几何、纹理、相机姿态和场景照明，获得全局一致的高质量三维重建模型与纹理。然而，该方法依赖于SFS，需要分解场景的光照，容易导致纹理拷贝问题。最近的工作中，Fu等人\upcite{YanpingFu2020JointTA}提出了一种基于颜色和几何一致性以及高频法线线索对重建网格进行优化的方法。这种方法有效地克服了SFS产生的纹理拷贝问题，得到了更高质量的重建结果。与之前只优化纹理的方法相比，在几何模型重建遇到细节缺失较大的情况下，这种方法仍然能产生清晰的纹理。受此方法启发，本文的第二个工作提出了联合优化框架，能够得到更加鲁棒的结果。\par

\vspace*{2mm}\noindent{\bf 基于深度学习的方法：}对抗生成网络GAN\upcite{NIPS2014_5ca3e9b1}在图像翻译\upcite{Imagetranslation}、新视角合成\upcite{NovelViewSynthesis}等领域大放异彩，可以生成与真实世界充分接近的高质量彩色图片。例如，优秀的开源框架pix2pix\upcite{isola2017image}和cycleGAN\upcite{zhu2017unpaired}等。受基于块合成纹理方法的启发，Huang等人\upcite{JingweiHuang2020AdversarialTO}使用从弱监督视图中获得的条件对抗损失，近似场景表面以生成逼真的纹理。使用基于学习的方法训练纹理目标函数，以保持对相机位姿和几何重建的鲁棒性。Zhang等人\upcite{9705143}同样借助于可微分渲染方法提出了一种联合优化方法，将几何、纹理和相机位姿共同纳入一个统一的优化框架中，并采用自适应交织策略，提高优化的稳定性和效率。虽然与本文方法类似，但本文在优化几何时额外采用自适应性细分策略。当几何误差过大时，本文方法仍能恢复出几何模型的细节，获取高保真的纹理。
%%----------------------
\section{本文的工作与安排}

\subsection{本文工作}
为了解决当前三维重建中纹理映射存在泛化能力差、瑕疵等问题，本文的研究主要集中在基于RGB-D相机的纹理映射方面。具体来说，本文从三维重建模型的纹理优化和联合优化两个方面展开了系统性的研究。\par

虽然生成对抗网络可以学习误差容忍度量，能够对几何、相机位姿、灯光等各项误差容忍，并生成貌似真实的纹理。但是，相机位姿误差过大时，生成的纹理结果仍然存在模糊和伪影等现象。为了解决这个问题，本文借助可微分渲染提出了一种矫正相机位姿的方法。该方法将模型顶点投影至所有可见的视角，得到渲染图像，并与真实采集的数据进行对比，以产生期望梯度来更新相机位姿。随后，使用矫正后的相机位姿，采用生成对抗网络GAN\upcite{chanmonteiro2020pi-GAN}重新合成纹理图集。本文方法在公共数据集上表现出较好的效果，相比传统方法，其泛化性和鲁棒性更强。\par

受 Fu 等人\upcite{YanpingFu2020JointTA} 联合优化方法的启发，本文借助可微分渲染方法来矫正几何模型顶点位置，以重塑模型形状。为了恢复重建几何模型的高频细节，本文提出自适应三角形细分方案，可增加顶点面片数以增强模型重建的合理性和精确性。此外，本文还提出交替优化策略：首先利用重投影误差矫正相机位姿，然后再矫正经过网格模型细分后的顶点位置，减少初始模型存在的几何误差以及数据集存在的大部分噪声。最后，借助生成对抗网络提升纹理细节，以得到高保真的纹理。实验证明本文的方法在各种场景中均能恢复出高保真的纹理，符合真实世界的三维模型的特征。

\subsection{结构安排}


本文的具体结构如下： \par
第一章 绪论。首先介绍基于 RGB-D 相机的三维重建和纹理映射的背景以及研究意义。其次，按时间顺序探讨本文相关的两个研究领域：基于 Fusion 的三维重建和纹理映射的研究现状。最后，介绍本文的研究思路和过程，以及论文的结构安排。\par
第二章 纹理优化相关技术介绍。在本章中，首先介绍数据获取设备，重建场景的表面表示，纹理表示与获取以及可微分渲染技术的原理。详细描述重建模型的各个部分与纹理映射的关系，以及对纹理映射结果的影响。\par
第三章 基于可微分渲染的纹理优化。本章首先利用可微分渲染技术矫正相机位姿，再借助对抗生成网络生成纹理图像，并在公共数据集上验证方法结果。对应于本文第一个工作。\par
第四章 基于自适应细分的重建模型与纹理优化。详细介绍针对 RGB-D 三维重建模型的联合优化算法，共同优化相机位姿、几何模型和纹理图集，并提出自适应三角形细分方案，增加顶点面片数目以增强模型重建的合理性和精确性。对应于本文的第二个工作。\par
第五章 总结与展望。总结本文主要研究内容，并对纹理优化方法未来的研究工作做出展望。

