% buaa基于ctexbook模板
% 模板选项:
%======================
% I.论文类型(thesis)
%--------------------
% a.学术硕士论文（master）[缺省值]
% b.专业硕士论文（professional）
% c.博士论文（doctor）
%--------------------
% II.密级(permission)
%--------------------
% a.公开（public）[缺省值]
% b.内部（privacy）
% c.秘密（secret=secret3）
% c.1.秘密3年（secret3）
% c.2.秘密5年（secret5）
% c.3.秘密10年（secret10）
% c.4.秘密永久（secret*）
% d.机密（classified=classified5）
% d.1.机密3年（classified3）
% d.2.机密5年（classified5）
% d.3.机密10年（classified10）
% d.4.机密永久（classified*）
% e.绝密（topsecret=topsecret10）
% e.1.绝密3年（topsecret3）
% e.2.绝密5年（topsecret5）
% e.3.绝密10年（topsecret10）
% e.4.绝密永久（topsecret*）
%--------------------
% III.打印设置(printtype)
%--------------------
% a.单面打印（oneside）[缺省值]
% b.双面打印（twoside）
%--------------------
% IV.系统类型(ostype)
%--------------------
% a.win（oneside）[缺省值]
% b.linux (linux)
% c.mac (mac)
%--------------------
% V.ctexbook设置选项(<ctexbookoptions>)
%--------------------
% ...
%======================
% 其他说明:
% 1. Mac系统请使用mac选项，并使用XeLaTeX编译。
% 2. 可加入额外ctexbook文档类的选项，其将会被传递给ctexbook。
%    例如：\documentclass[fontset=founder]{buaa}
% 3. CTeX在Linux下默认使用Fandol字体，为避免某些生僻字无法显示，在系统已安装方正
%    字体的前提下可通过fontset=founder选项常用方正字体。
%=================================================================
% buaa模板已内嵌以下LaTeX工具包:
%--------------------
% ifthen, etoolbox, titletoc, remreset,
% geometry, fancyhdr, setspace,
% float, graphicx, subfigure, epstopdf,
% array, enumitem,
% booktabs, longtable, multirow, caption,
% listings, algorithm2e, amsmath, amsthm,
% hyperref, pifont, color, soul,
% ---
% For Win: times
% For Lin: newtxtext, newtxmath
% For Mac: times, fontspec
%--------------------
% 请在此处添加额外工具包>>
%=================================================================
% buaa模板已内嵌以下LaTeX宏:
%--------------------
% \highlight{text} % 黄色高亮
%--------------------
% 请在此处添加自定义宏>>
%%=================================================================


\documentclass[master,public,oneside,win,AutoFakeBold]{buaa}


%=================================================================
% 开启/关闭引用编号颜色：参考文献，公式，图，表，算法 等……
%\refcolor{on}   % 开启: on[默认]; 关闭: off;

% 摘要和正文从右侧页开始
\beginright{on} % 开启: on[默认]; 关闭: off;

%盲评模式，开启后不显示学校等信息 ，注意自行修改致谢和学术成果
\blindmode{on}   % 开启: on; 关闭: off[默认];

% 空白页留字
\emptypagewords{[ -- This page is a preset empty page -- ]}

% 不显示超链接方框
%\hypersetup{hidelinks}

%=================================================================
% 论文题目及副标题-{中文}{英文}
\Title{基于可微分渲染的三维重建与纹理优化}{3D Reconstruction and Texture Optimization Based on Differentiable Rendering}
%\Subtitle{学位论文~\LaTeX{}模板}

% 学位级别
\Branch{工学硕士}

% 院系,专业及研究方向
\Department{计算机科学与技术学院}
% 一级学科/学科专业
\Major{计算机科学与技术}
% 二级学科
\Majorsec{计算机科学与技术}
%研究方向
\Field{纹理优化}

% 导师信息-{中文名}{英文名}{职称}
\Tutor{赵海峰}{Zhao Haifeng}{教授}
%\Cotutor{付燕平}{Fu Yanping}{教师}

% 学生姓名-{中文名}{英文名}
\Author{刘勇鑫}{Liu Yongxin}
% 论文编号
\StudentID{10357B00000000}

% 中图分类号
\CLC{AB00}

% 时间节点-{月}{日}{年}
%入学时间
\DateEnroll{09}{01}{2020}
%毕业时间
\DateGraduate{07}{01}{2023}
%论文提交日期
\DateSubmit{03}{01}{2023}
%论文答辩日期
\DateDefence{05}{21}{2023}

%%=================================================================
% 摘要-{中文}{英文}
\Abstract{%
	三维重建是VR/AR、动画游戏等领域的重要应用之一，需要实现高保真的纹理映射和精细的几何重建。然而，现有的三维重建算法在重建过程中会遭受各种噪声的影响，导致重建模型细节上的缺失，无法直接应用到以上场景中。三维重建结果与实际需求不匹配，受以下几个因素的的影响和破坏：（1）深度相机测量物体深度时，易受到运动模糊、相机抖动、光源干扰等因素影响，导致出现度量误差。（2）相机位姿估计时，估计误差会不断累计并传递至下一帧，即使有回环检测和回环矫正，也不能保证相机位姿估计完全正确。（3）三维重建算法通常采用截断符号距离场来表示重建模型，并应用加权平均策略来降低数据噪声。这种加权平均策略会在一定程度上降低几何细节的复杂性，从而使得重建模型表面变得平滑，失去模型本来的高频几何细节。这往往导致重建的三维模型与真实场景在几何形状上存在误差。\par
	针对三维重建过程中存在的挑战，本文基于可微分渲染提出了一个端到端的优化方法，对相机姿态和纹理进行改进。首先，使用光度一致性纠正几何模型顶点到每个视角的映射关系，然后利用对抗神经网络学习误差容忍度量，容忍纹理重建过程中存在的各种误差。本文方法经过实验证明能够消除初始纹理存在的缺陷，如模糊、伪影和裂缝等。相比于传统方法，本文方法适用于各种具有挑战性的场景，并且可以弥补传统方法泛化能力不足的缺陷。\par
	虽然矫正相机位姿与纹理重合成算法可以降低纹理映射中的位姿误差和噪声影响，但是当重建模型存在严重错位或几何细节缺失时，难以达到理想效果。因此，本文提出了基于可微分渲染的几何模型优化方法，它能够通过更新几何模型的顶点位置来重建模型的表面形状。此外，本文采用基于三角形质心的自适应细分方法，以增加几何模型表面的平滑度，从而更容易恢复高频几何细节。最后，本文基于可微分渲染提出了一个联合优化深度学习框架，对相机位姿、纹理和几何模型进行联合优化。这种联合优化方式能够克服单独优化某一因素难以达到全局最优解的限制，从而得到高质量的重建模型。实验结果表明，在公共数据集上，本文提出的联合优化框架相比于其他最新纹理优化方法，在恢复三维重建模型高质量几何细节和高保真纹理细节方面表现更好。
}
{%
	3D reconstruction is one of the important applications in VR/AR, animation and gaming industries, requiring high-fidelity texture mapping and fine geometric reconstruction. However, existing 3D reconstruction algorithms are often affected by various noise during the reconstruction process, leading to missing details in the reconstructed model that cannot be applied directly to the above-mentioned scenarios. Three-dimensional reconstruction results often do not match actual requirements due to the following factors: (1) when measuring the depth of objects using a depth camera, errors can easily occur due to factors such as motion blur, camera shake, and light source interference. (2) When estimating camera pose, estimation errors accumulate and propagate to the next frame, and even with loop closure detection and correction, camera pose estimation cannot be guaranteed to be entirely accurate. (3) 3D reconstruction algorithms usually adopt truncated signed distance fields to represent the reconstructed model, and apply weighted averaging strategies to reduce data noise. Such averaging strategies can reduce the complexity of geometric details to some extent, resulting in a smoother surface of the reconstructed model, losing the high-frequency geometric details of the model itself. This often leads to geometric errors between the reconstructed 3D model and the real scene.\par
    This thesis proposes an end-to-end optimization method based on differentiable rendering to address the challenges in the 3D reconstruction process, improving camera pose estimation and texture mapping. Firstly, photometric consistency is utilized to correct the vertex-to-view mapping in the geometric model. Secondly, an adversarial neural network is used to learn error tolerance metrics, allowing various errors to be tolerated during the texture reconstruction process. Experimental results show that our method can effectively eliminate initial texture defects such as blurriness, pseudoshadows, and cracks. Compared with traditional methods, our approach is applicable to challenging scenarios and can compensate for the lack of generality in traditional methods.\par
	Although the method of correcting camera pose and texture synthesis can reduce the pose error and noise in texture mapping, it is difficult to achieve the desired effect when the reconstructed model has serious misalignment or geometric detail missing. Therefore, this thesis proposes a geometry model optimization method based on differentiable rendering, which can rebuild the surface shape of the model by updating the vertex positions of the geometry model. In addition, this thesis adopts an adaptive subdivision method based on triangle centroid to increase the surface smoothness of the geometry model, making it easier to recover high-frequency geometric details. Finally, based on differentiable rendering, this thesis proposes a joint optimization deep learning framework to jointly optimize camera pose, texture and geometry model. This joint optimization method can overcome the limitation of optimizing a single factor and difficult to achieve global optimal solution, thus obtaining high-quality reconstructed models. Experimental results show that, on public datasets, the joint optimization framework proposed in this thesis performs better in restoring high-quality geometric details and high-fidelity texture details of 3D reconstruction models compared to other state-of-the-art texture optimization methods.
}
\vspace{-5em}

% 关键字-{中文}{英文}
\Keyword{%
三维重建，纹理映射，相机位姿估计，可微分渲染
}{%
	3D reconstruction,Texture mapping,Camera pose estimation,Differentiable rendering
}



% 图表目录
\Listfigtab{on} % 启用: on[默认]; 关闭: off;


% 缩写定义 按tabular环境或其他列表环境编写
%\Abbreviations{ \centering
%\begin{tabular}{cl}
%  $E$ & 能量 \\
%  $m$ & 质量 \\
%  $c$ & 光速 \\
%  $P$ & 概率 \\
%  $T$ & 时间 \\
%  $v$ & 速度 \\
%\end{tabular}
%}

% \PassOptionsToPackage{gbnamefmt=lowercase}{biblatex}
% \usepackage[backend=biber,style=numeric,sorting=none,gbpub=false,bibstyle=gb7714-2015,citestyle=gb7714-2015]{biblatex}
% \addbibresource[location=local]{ref.bib}


\begin{document}

%%=================================================================
% 标题级别
%--------------------
% \chapter{第一章}
% \section{1.1 小节}
% \subsection{1.1.1 条}
% \subsubsection{1.1.1.1}
% \paragraph{1.1.1.1.1}
% \subparagraph{1.1.1.1.1.1}
%--------------------
%%=================================================================

% 绪论
\input{tex/chap_intro}

% 说明
\input{tex/chap_instruction}

% 示例

\input{tex/chap_work1.tex}
\input{tex/chap_work2.tex}

\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
% 总结与展望
\input{tex/chap_summary}

% 参考文献
% 2015版国标GBT7714-2015
% 2005版国标GBT7714-2005

% 用.bib文件形式引入参考文献
%\Bib{bst/GBT7714-2015}{ref}

%手动添加参考文献
\bib
\begin{thebibliography}{00}
\input{tex/References}
\end{thebibliography}



















  
% 附录
% \input{tex/chap_appendix}

% 攻读学位期间成果
\input{tex/chap_achievement}

% 攻读学位参与的科研项目
\input{tex/chap_program}



% 致谢
%\input{tex/chap_acknowledge}

% 作者简介
%\input{tex/chap_biography}

\end{document} 