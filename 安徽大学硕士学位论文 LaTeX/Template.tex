% buaa基于ctexbook模板
% 模板选项:
%======================
% I.论文类型(thesis)
%--------------------
% a.学术硕士论文（master）[缺省值]
% b.专业硕士论文（professional）
% c.博士论文（doctor）
%--------------------
% II.密级(permission)
%--------------------
% a.公开（public）[缺省值]
% b.内部（privacy）
% c.秘密（secret=secret3）
% c.1.秘密3年（secret3）
% c.2.秘密5年（secret5）
% c.3.秘密10年（secret10）
% c.4.秘密永久（secret*）
% d.机密（classified=classified5）
% d.1.机密3年（classified3）
% d.2.机密5年（classified5）
% d.3.机密10年（classified10）
% d.4.机密永久（classified*）
% e.绝密（topsecret=topsecret10）
% e.1.绝密3年（topsecret3）
% e.2.绝密5年（topsecret5）
% e.3.绝密10年（topsecret10）
% e.4.绝密永久（topsecret*）
%--------------------
% III.打印设置(printtype)
%--------------------
% a.单面打印（oneside）[缺省值]
% b.双面打印（twoside）
%--------------------
% IV.系统类型(ostype)
%--------------------
% a.win（oneside）[缺省值]
% b.linux (linux)
% c.mac (mac)
%--------------------
% V.ctexbook设置选项(<ctexbookoptions>)
%--------------------
% ...
%======================
% 其他说明:
% 1. Mac系统请使用mac选项，并使用XeLaTeX编译。
% 2. 可加入额外ctexbook文档类的选项，其将会被传递给ctexbook。
%    例如：\documentclass[fontset=founder]{buaa}
% 3. CTeX在Linux下默认使用Fandol字体，为避免某些生僻字无法显示，在系统已安装方正
%    字体的前提下可通过fontset=founder选项常用方正字体。
%=================================================================
% buaa模板已内嵌以下LaTeX工具包:
%--------------------
% ifthen, etoolbox, titletoc, remreset,
% geometry, fancyhdr, setspace,
% float, graphicx, subfigure, epstopdf,
% array, enumitem,
% booktabs, longtable, multirow, caption,
% listings, algorithm2e, amsmath, amsthm,
% hyperref, pifont, color, soul,
% ---
% For Win: times
% For Lin: newtxtext, newtxmath
% For Mac: times, fontspec
%--------------------
% 请在此处添加额外工具包>>
%=================================================================
% buaa模板已内嵌以下LaTeX宏:
%--------------------
% \highlight{text} % 黄色高亮
%--------------------
% 请在此处添加自定义宏>>
%%=================================================================

\documentclass[master,public,twoside,win,AutoFakeBold]{buaa}

%=================================================================
% 摘要和正文从右侧页开始，单面打印请关闭
\beginright{off} % 开启: on; 关闭: off[默认];

%盲评模式，开启后不显示学校等信息 ，注意自行修改致谢和学术成果
\blindmode{off}   % 开启: on; 关闭: off[默认];

% 空白页留字
\emptypagewords{[ -- This page is a preset empty page -- ]}

% 不显示超链接方框
\hypersetup{hidelinks}

%=================================================================
% 论文题目及副标题-{中文}{英文}
\Title{基于可微分渲染的几何模型重建与纹理优化}{Geometric model reconstruction and texture optimization based on differentiable rendering}
%\Subtitle{学位论文~\LaTeX{}模板}

% 学位级别
\Branch{工学硕士}

% 院系,专业及研究方向
\Department{计算机科学与技术学院}
% 一级学科/学科专业
\Major{计算机科学与技术}
% 二级学科
\Majorsec{计算机科学与技术}
%研究方向
\Field{纹理优化}

% 导师信息-{中文名}{英文名}{职称}
\Tutor{赵海峰}{Zhao Haifeng}{教授}
\Cotutor{付燕平}{Fu Yanping}{教师}

% 学生姓名-{中文名}{英文名}
\Author{刘勇鑫}{Liu Yongxin}
% 论文编号
\StudentID{10357B00000000}

% 中图分类号
\CLC{AB00}

% 时间节点-{月}{日}{年}
%入学时间
\DateEnroll{09}{01}{2020}
%毕业时间
\DateGraduate{07}{01}{2023}
%论文提交日期
\DateSubmit{03}{01}{2023}
%论文答辩日期
\DateDefence{05}{21}{2023}

%%=================================================================
% 摘要-{中文}{英文}
\Abstract{%
	实现高保真的纹理映射和和精确的几何重建是三维重建领域的重要课题，因为它在VR/AR、动画游戏等领域都有广阔的应用前景。虽然手持RGB-D相机出现可以方便地进行室内场景的三维重建，但是现有的三维重建算法在重建过程中会遭受各种噪声的影响，导致重建模型和细节上的缺失，因而无法直接应用到在以上真实场景中。以上需求很容易受到以下因素的影响和破坏:(1）深度相机获取的深度时很容易受到噪音、镜头扭曲和量化误差等因素的影响,造成深度测量出现度量误差。(2)在相机位姿估计时很容易出现相机累积误差造成相机位姿漂移。(3)现有的三维重建算法普遍采用TSDF(truncated signed distance field)数据融合技术来进行三维数据融合和表示，它虽然可以利用加权平均来消除大部分的噪音，但是也会平滑掉很多高频的几何细节使得模型趋于平滑，而造成重建的模型出现几何误差。\par
	对于以上挑战，本文从相机位姿矫正、几何模型细化以及纹理图重生成方面对三维重建模型和纹理进行优化。首先本文借助于可微分渲染方法，我们提出了一个端到端的优化算法，首先利用光度一致性对齐几何模型顶点到每个视角的映射关系，然后用对抗神经网络学习误差容忍度量，容忍纹理重建过程中存在的各中误差，经过实验证明我们的方法能够消除纹理优化中存在的模糊、伪影、裂缝等现象。相比于传统方法我们的方法适用于各种场景，能够弥补传统方法泛化性等缺陷。\par
	
	然而单纯依赖神经网络弥补纹理映射中的误差，难以达到理想效果，例如几何模型严重缺失。我们利用可微分渲染优化几何模型，减小重建模型中的几何误差。不仅如此，为了恢复几何模型的高频细节，我们利用自适应细分方法提升模型重建质量。最后提出一个基于可微分渲染的联合优化深度学习框架，同时对相机位姿与纹理，细化和重建模型进行联合。克服现有只对一个因素进行优化而难以达到全局最优解的障碍,并最终得到带有高质量几何细节和高保真纹理的三维重建结果。实验结果表明，与最先进的方法相比，我们的联合优化框架相比于最新纹理优化方法在合成数据上的定量和真实数据上的定性上都产生了显著的性能提高。也展示了我们在恢复出三维重建模型高质量的几何细节和高保真的纹理细节方面具有优势。
}
{%
	Achieving high-fidelity texture mapping and and accurate geometric reconstruction is an important topic in the field of 3D reconstruction because it has broad application prospects in VR/AR, animation games and other fields. Although the emergence of handheld RGB-D cameras can facilitate 3D reconstruction of indoor scenes, existing 3D reconstruction algorithms suffer from various noises during the reconstruction process, resulting in the lack of reconstruction models and details, and thus cannot be directly applied to in the above real scenes. The above requirements are easily affected and damaged by the following factors: (1) The depth acquired by the depth camera is easily affected by noise, lens distortion and quantization errors, resulting in metric errors in depth measurement. (2) In the camera pose estimation is easy to have camera cumulative error caused by camera pose drift. (3) The existing 3D reconstruction algorithms generally use TSDF (truncated signed distance field) data fusion technique to fuse and represent 3D data, which can eliminate most of the noise by using weighted average, but also smooth out many high frequency geometric details to make the model tend to be smooth, and cause geometric errors in the reconstructed model.\par
	For the above challenges, this paper optimizes the 3D reconstructed model and textures in terms of camera pose correction, geometric model refinement, and texture map regeneration. Firstly, we propose an end-to-end optimization algorithm with the help of differentiable rendering method. Firstly, we use photometric consistency to align the mapping relations from the geometric model vertices to each viewpoint, and then we use adversarial neural network to learn the error tolerance metric to tolerate each medium error in the texture reconstruction process. Compared with traditional methods our method is applicable to various scenes and can make up for the deficiencies such as generalizability of traditional methods.\par
	However, relying solely on neural networks to compensate for errors in texture mapping is difficult to achieve the desired effect, for example, the geometric model is severely missing. We optimize the geometric model using differentiable rendering to reduce the geometric errors in the reconstructed model. In addition, to recover the high-frequency details of the geometric model, we use an adaptive subdivision method to improve the model reconstruction quality. Finally, we propose a joint optimization deep learning framework based on differentiable rendering to simultaneously combine camera poses with textures, refinement and reconstructed models. We overcome the existing obstacle of optimizing only one factor to achieve the global optimal solution, and finally obtain 3D reconstruction results with high quality geometric details and high fidelity textures. Experimental results show that our joint optimization framework yields significant performance improvements over state-of-the-art methods in both quantitative on synthetic data and qualitative on real data compared to state-of-the-art texture optimization methods. It also demonstrates our advantage in recovering high quality geometric details and high fidelity texture details from 3D reconstructed models.
}
% 关键字-{中文}{英文}
\Keyword{%
	纹理优化，RGB-D重建，可微分渲染，相机位姿
}{%
	Texture optimization, RGB-D reconstruction, differentiable rendering, camera pose
}


% 图表目录
\Listfigtab{off} % 启用: on[默认]; 关闭: off;

% 缩写定义 按tabular环境或其他列表环境编写
%\Abbreviations{ \centering
%\begin{tabular}{cl}
%  $E$ & 能量 \\
%  $m$ & 质量 \\
%  $c$ & 光速 \\
%  $P$ & 概率 \\
%  $T$ & 时间 \\
%  $v$ & 速度 \\
%\end{tabular}
%}

\begin{document}

%%=================================================================
% 标题级别
%--------------------
% \chapter{第一章}
% \section{1.1 小节}
% \subsection{1.1.1 条}
% \subsubsection{1.1.1.1}
% \paragraph{1.1.1.1.1}
% \subparagraph{1.1.1.1.1.1}
%--------------------
%%=================================================================

% 绪论
\input{tex/chap_intro}

% 说明
\input{tex/chap_instruction}

% 示例

\input{tex/chap_work1.tex}
\input{tex/chap_work2.tex}

\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
% 总结与展望
\input{tex/chap_summary}

% 参考文献
% 2015版国标GBT7714-2015
% 2005版国标GBT7714-2005

%\Bib{bst/GBT7714-2015}{ref}
\bibliographystyle{plain}
\bibliography{ref}

% 附录
\input{tex/chap_appendix}

% 攻读学位期间成果
\input{tex/chap_achievement}

% 致谢
\input{tex/chap_acknowledge}

% 作者简介
%\input{tex/chap_biography}

\end{document} 